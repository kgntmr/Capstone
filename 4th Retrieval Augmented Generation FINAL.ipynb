{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "kf0WMTIt7_XW"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain langchain-chroma langchain-openai chroma langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MolCS8DpD4rY",
        "outputId": "245d365e-8a31-4675-894c-e3e2ec895790"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "import getpass\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from transformers import pipeline\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the question-answering pipeline from the Fine-Tuned model\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"kgntmr/RoBERTa-SQuAD2.0-SubjQA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW8sy8AND4rZ",
        "outputId": "b1adf0e8-aa8a-4e0a-e05c-80073dfdf8d0"
      },
      "outputs": [],
      "source": [
        "# Get API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aDa0vwBLD4rZ"
      },
      "outputs": [],
      "source": [
        "# Define the WebBaseLoader class\n",
        "class WebBaseLoader:\n",
        "    # Constructor to initialize the WebBaseLoader object with web_paths and bs_kwargs\n",
        "    def __init__(self, web_paths, bs_kwargs):\n",
        "        self.web_paths = web_paths  # Stores a list of URLs to be processed\n",
        "        self.bs_kwargs = bs_kwargs  # Stores additional arguments for BeautifulSoup\n",
        "\n",
        "    # Method to load data from each web path and parse the HTML content\n",
        "    def load(self):\n",
        "        results = {}  # Dictionary to store the results of web scraping\n",
        "        for url in self.web_paths:  # Iterating over each URL in the web_paths list\n",
        "            try:\n",
        "                response = requests.get(url)  # Sending a GET request to the URL\n",
        "                if response.status_code == 200:  # Checking if the request was successful\n",
        "                    # Parsing the HTML content with BeautifulSoup using the provided arguments\n",
        "                    soup = BeautifulSoup(response.text, 'html.parser', **self.bs_kwargs)\n",
        "                    results[url] = soup.get_text()  # Extracting text from the parsed HTML and storing it in the results dictionary\n",
        "                else:\n",
        "                    results[url] = None  # Storing None if the response was unsuccessful\n",
        "            except requests.RequestException as e:  # Handling exceptions that may occur during the GET request\n",
        "                results[url] = str(e)  # Storing the exception message as the result for the URL\n",
        "        return results  # Returning the dictionary containing the results of the web scraping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gOPHTrGwD4rZ"
      },
      "outputs": [],
      "source": [
        "# Function definition to fetch and return text content from specified website URLs using a given set of selector attributes\n",
        "def fetch_website_text(urls, selector_attrs):\n",
        "    # Creating a SoupStrainer object that filters out all unnecessary data except for elements matching the provided attributes\n",
        "    strainer = bs4.SoupStrainer(**selector_attrs)\n",
        "    # Initializing the WebBaseLoader with the URLs and the strainer object to parse only necessary parts of HTML\n",
        "    loader = WebBaseLoader(web_paths=urls, bs_kwargs={\"parse_only\": strainer})\n",
        "    # Calling the 'load' method from the WebBaseLoader instance to fetch and parse the web pages\n",
        "    return loader.load()\n",
        "\n",
        "# List of URLs from which to scrape data\n",
        "urls = [\n",
        "    \"https://www.theguardian.com/technology/2016/may/03/amazon-fresh-food-deliveries-understood-to-start-this-month\",\n",
        "    \"https://www.theguardian.com/media/2016/may/16/bbc-netflix-rival-itv-nbc-universal\",\n",
        "    \"https://www.theguardian.com/technology/2016/apr/28/amazon-most-profitable-quarter-sales-up-costs\",\n",
        "    \"https://www.theguardian.com/technology/2016/apr/26/amazon-kindle-oasis-review-luxury-e-reader\",\n",
        "    \"https://www.theguardian.com/environment/andes-to-the-amazon/2016/may/25/london-stock-exchange-amazon-deforestation\",\n",
        "    \"https://www.theguardian.com/media/2016/may/25/netflix-and-amazon-must-guarantee-20-of-content-is-european\",\n",
        "    \"https://www.theguardian.com/technology/2016/may/26/amazon-echo-virtual-assistant-child-privacy-law\",\n",
        "]\n",
        "# Dictionary specifying the attributes to filter HTML elements using SoupStrainer\n",
        "selector_attrs = {\"class\": \"article-body-commercial-selector\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U066izP1Sy5q"
      },
      "source": [
        "### The function fetch_website_text is now ready to be called with the list of URLs and selector attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dhkRHILWD4ra"
      },
      "outputs": [],
      "source": [
        "# Initialize the WebBaseLoader with URLs and BeautifulSoup keyword arguments\n",
        "loader = WebBaseLoader(urls, {\"parse_only\": bs4.SoupStrainer(**selector_attrs)})\n",
        "\n",
        "# Load the content from the specified URLs\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DGu7hfy2D4ra"
      },
      "outputs": [],
      "source": [
        "# Definition of the RecursiveCharacterTextSplitter class\n",
        "class RecursiveCharacterTextSplitter:\n",
        "    def __init__(self, chunk_size, chunk_overlap):\n",
        "        self.chunk_size = chunk_size  # The number of characters in each text chunk\n",
        "        self.chunk_overlap = chunk_overlap  # The number of characters each chunk overlaps with the next\n",
        "\n",
        "    def split_document(self, text):\n",
        "        return [text[i:i + self.chunk_size] for i in range(0, len(text), self.chunk_size - self.chunk_overlap)]\n",
        "\n",
        "    def split_documents(self, documents):\n",
        "        splits = []  # List to hold all chunks from all documents\n",
        "        for doc in documents:  # Iterating over each document in the provided list\n",
        "            if isinstance(doc, str):\n",
        "                text = doc  # Directly assigns the document to text if it is a string\n",
        "            else:\n",
        "                text = getattr(doc, 'page_content', '')  # Attempts to fetch 'page_content' from the document object; defaults to empty string if not found\n",
        "            splits.extend(self.split_document(text))  # Adds the chunks from the current document to the splits list\n",
        "        return splits  # Returns the list of all chunks from all documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dDJtS21YTF6m"
      },
      "outputs": [],
      "source": [
        "# Creating an instance of RecursiveCharacterTextSplitter with a chunk size of 1000 characters and an overlap of 200 characters\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "# Splitting a list of documents into smaller, overlapping chunks to maintain context between sections\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Initializing a vector store to enable semantic search capabilities using embeddings from OpenAI\n",
        "vectorstore = Chroma.from_texts(texts=splits, embedding=OpenAIEmbeddings())\n",
        "# Creating a retriever from the vector store for efficient information retrieval\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Retrieving a pre-defined prompt designed for use with language models in a retrieval-augmented generation setup\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to format strings from a list of documents into a single string\n",
        "def format_strings(documents):\n",
        "    formatted_documents = []  # List to hold formatted documents\n",
        "    for doc in documents:  # Iterate through each document in the input list\n",
        "        if isinstance(doc, str):\n",
        "            formatted_documents.append(doc)  # Add the string directly if the document is a string\n",
        "        elif isinstance(doc, dict):\n",
        "            # If the document is a dictionary, retrieve the value of 'page_content', defaulting to an empty string if not found\n",
        "            formatted_documents.append(doc.get('page_content', ''))\n",
        "        else:\n",
        "            # Append an empty string if the document is neither a string nor a dictionary\n",
        "            formatted_documents.append('')\n",
        "    # Join all formatted documents into a single string, separated by two newlines\n",
        "    return \"\\n\\n\".join(formatted_documents)\n",
        "\n",
        "# Usage of the function to format a list of documents\n",
        "formatted_context = format_strings(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: amazon-fresh-food\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "`question` cannot be empty",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Main function to handle the application's execution flow\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 21\u001b[0m     \u001b[43muser_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[18], line 10\u001b[0m, in \u001b[0;36muser_interface\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Process the user's question using the retrieval-augmented generation pipeline\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatted_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n",
            "Cell \u001b[1;32mIn[18], line 16\u001b[0m, in \u001b[0;36mrag_answer\u001b[1;34m(question, context)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrag_answer\u001b[39m(question, context):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Generate answer using the RAG pipeline\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mqa_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:391\u001b[0m, in \u001b[0;36mQuestionAnsweringPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03mAnswer the question(s) given as inputs by using the context(s).\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    - **answer** (`str`) -- The answer to the question.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# Convert inputs to features\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(examples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:219\u001b[0m, in \u001b[0;36mQuestionAnsweringArgumentHandler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inputs):\n\u001b[1;32m--> 219\u001b[0m     inputs[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
            "File \u001b[1;32mc:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:169\u001b[0m, in \u001b[0;36mQuestionAnsweringArgumentHandler.normalize\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item[k], \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(item[k]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 169\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QuestionAnsweringPipeline\u001b[38;5;241m.\u001b[39mcreate_sample(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mitem)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m argument needs to be of type (SquadExample, dict)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: `question` cannot be empty"
          ]
        }
      ],
      "source": [
        "# Define the User Interface for RAG based on the user's queries\n",
        "def user_interface():\n",
        "    while True:\n",
        "        # User input for the question\n",
        "        question = input(\"Ask a question about Amazon between April and June 2016 (or type 'exit' to quit): \")\n",
        "        if question.lower() == 'exit':\n",
        "            print(\"Exiting the program.\")\n",
        "            break\n",
        "        # Process the user's question using the retrieval-augmented generation pipeline\n",
        "        response = rag_answer(question, formatted_context)\n",
        "        print(\"Answer:\", response)\n",
        "\n",
        "# Function to generate answers using the RAG pipeline and provided context\n",
        "def rag_answer(question, context):\n",
        "    # Generate answer using the RAG pipeline\n",
        "    answer = qa_pipeline(question=question, context=context)\n",
        "    return answer['answer']  # Return only the 'answer' part of the result\n",
        "\n",
        "# Main function to handle the application's execution flow\n",
        "if __name__ == \"__main__\":\n",
        "    user_interface()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
